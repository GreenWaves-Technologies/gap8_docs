
# CIFAR10 image recognition

## Introduction

This document describes a CIFAR10 image recognition application based on a convolutional neural network (CNN) on the GAP8 processor.
The example can be compiled and executed on the virtual model of GAP8 available in the SDK.

In the example, 32x32 pixels images are captured from a camera model by the camera interface and loaded in the L2 memory of the fabric controller.
The images are then processed by the CNN on the 8 cores of the cluster. The CNN classifies the images in 10 categories, by selecting the maximum confidence value at the output as the inferred category.

The network topology (number of layers, number of inputs and outputs for the layers) has been taken from an open source project on the Internet. In this example, we demonstrate the implementation 
of this network on GAP8 using adapted data management through DMA and optimized parallelized filter kernels taking benefits of the 8 cores of the cluster.

The CNN has been trained off-line using the CIFAR10 dataset. The recognition ratio reached after training is 68%, which is very close to the asymptotic ratio announced by the authors.
Actually more sophisticated topologies can achieve a better rate, but this example is given more as a simpler tutorial for CNN implementation principles on GAP8 architecture.
Specifically, it demonstrates how to perform data management between L2 memory in the fabric controller and the L1 cluster shared memory so that no memory overflow occurs while keeping all the compute resources busy.
It also shows how the basic filter kernels (2D convolution filter and linear filters) can be described to use the 8 cores of the cluster efficiently so as to reduce computation time and hence power consumption of the application.

In the next sections, we will describe the structure of the example directory, the structure of the CNN and its software components and finally how to run the application on the GAP8 simulator.

## Structure of the directory

In the GAP8 installation repository, the cifar10 example is located in:

  app_release/applications/cifar10/

The directory contains the following files:

    main_cam.c 	       : main application code
    cnn_process.c      : cnn network code
    Makefile	: compilation and execution command file
    l2_data.h	: allocation of data stored in L2
    RGB.img 	: one test image in RGB565 format
    run_script.sh	: script to run executions on different test images
    inc_gen/L2.h	: biases and weights for the CIFAR10 CNN quantized
                      with a Q14 representation
    test_img 	: 10 32x32 pixels images from the CIFAR10 test dataset
    src_lib		: library of kernels and functions for CNNs
    CnnKernels.c(h)	: Functions of the CNN layers
    CnnKernelsInit.ch	: parameters for the CNN layer functions
    gen_lib_save	: Directory for the saved reference generated files

##Description of the CNN

The CNN is composed of three layers, described in the procedure `network_process()` of the main_cam.c file:

***One 2 Dimension convolution layer with one input 32x32 ReLU and 2x2 max pooling producing 8 outputs 14x14 samples***

~~~~c
ConvLayer(l2_x, L2_W_0, l2_big0, 14, L2_B_0, AllKernels); 
~~~~

Each layer is called a "Kernel" in the following.
A kernel is executed on the cluster. It is launched by the fabric controler, and it encapsulates all the DMA transfers and sync functions to execute the function on the 8 cores of the cluster.
It can be either generated by the autotiler or taken from the gen_lib_save directory

ConvLayer is a *kernel* function that manages data transfers and 2D convolution filter execution on the input l2_x. It is described in the CnnKernels_newrt.c file where:

+ l2_x is a pointer to the buffer containing the input image loaded from the camera
+ L2_W_0 is a pointer to the convolution filter kernel coefficients
+ L2_B_0 is a pointer to the biases
+ l2_big0 is a pointer to the buffer containing the results of the 2D convolution filter for all output features
+ AllKernels is the structure containing the parameters for the kernel function, this structure is defined in the CnnKernelsInit.c file.  

***One 2 Dimension Convolution layer with 8 inputs and 32 outputs 5x5, ReLU and 2x2 max pooling producing 32 outputs of 5x5 samples***

~~~~c
ConvLayer(l2_big0, L2_W_2, l2_big1, 14, L2_B_2, AllKernels+1);
~~~~

Same as above, with the difference that the input is l2_big0, and the output l3_big1.

***One Dense/fully connected layer with 3000 inputs and 10 outputs***

~~~~c
Dense(l2_big1, L2_W_4, 16, L2_B_4, 13, l2_big0, 10, AllKernels+2); 
~~~~

This *kernel* function manages data transfers and linear filtering of the input l2_big1. It is described in the Cnnkernels.c file.

+ L2_W_4 points to the weights
+ L2_B_4 points to the biases
+ l2_big0 points to the output
+ AllKernels+2 points to the arguments of the kernel function.

Note that all structures (l2_x, l2_big*, L2_W_*, L2_B_* are located in the L2 memory of the fabric controller), while the kernels are executed on the cluster. Data is transfered to the L1 memory by the DMA processes described in the ConvLayer and Dense kernel functions.

## Automatic layer code generation

### Cifar10 with automatic tiling generation

For this cifar10 example, the low level code for the CNN layers (convolutional and dense linear layers) has been generated using the auto-tiling tool available in this SDK.

The generator assumes that the data and weights are stored on the L2 memory (in the Fabric Controller). The available size of L1 shared memory for processing is specified to the tiler.
The data and weights are split into tiles, forming  data sets that will be loaded through DMA to the L1 shared memory of the cluster. The cores will process the data and when finished, the results are stored back into the L2.
The tool takes the "high level" parameters of the layers as input and generates the low level functions describing the data management and the sync run time functions to execute the layers in parallel on the eight cores of the cluster.

Data transfers and processing are pipelined. Doing so, the DMA processes and the data processing can be executed in parallel on different data sets to optimize the execution time.

The following files are automatically generated:
- CnnKernels.c	    : contains the generated code for the layers, with the calls to run time DMA process and processor synchronization
- CnnKernel.h	      : contains the header for Convlayer and dense layer functions
- CnnKernelInit.c   : Contains the parameters for the DMA transfers and processing, including the tiling management and pipeline processing
- CnnKernelsInit.h  : contains data-type definition for the parameter structures

### How to automatically generate the CIFAR10 CNN code with tiling 

The input file containing the "high level" description of the layers used in cifar10 is Model_kernel.c.

Following is the description of the different sections in the input file:

~~~~~c
  SetInlineMode(SINGLE_INLINE);
~~~~~

This instruction specifies that a single function will be generated if several occurrences of it are generated.

In this case, a structure containing the execution parameters is passed to the function.  The parameters are defined in the CnnKernelInit.c file.
To Generate one function per call the argument to pass to the SetInlineMode function is "ALWAYS_INLINE".

The following instructions specify the name of the library header files (SetUsedFIlesNames), the names of the generated files (SetGeneratedFilesNames), and the declaration of the amount of L1 memory to be used by the auto-tiler generator.

~~~~~c
  SetUsedFilesNames("KernelLibStdTypes.h",1 , "CNN_BasicKernels.h");
  SetGeneratedFilesNames("CnnKernelsInit.c", "CnnKernelsInit.h", "CnnKernels.c", "CnnKernels.h");
  
  SetL1MemorySize(L1Memory);
~~~~~

The kernel libraries are loaded for usage by the tiler:

~~~~~c
  CNN_LoadSoftwareKernelLibrary();
  CNN_LoadHWCEKernelLibrary();
~~~~~

The layer parameters are defined by the code below: 

~~~~~c
  // cifar10 config 
  CNN_TiledConvNxNReLUPool2x2_SW_fp("ConvLayer", 5, 1, 8, 32, 32, 3);
  CNN_TiledConvNxNReLUPool2x2_SW_fp("ConvLayer", 5, 8, 12, 14, 14, 3);
  CNN_TiledLinearLayer     ("Dense", 12, 5, 5, 10, 1, 0, 0);
~~~~~

CNN_TiledConvNxNReLUPool2x2_SW_fp: defines a 2D Conv layer with ReLU and pooling. The parameters are, in order:

+ "ConvLayer": The name of the generated function 
+  5: size of the kernel (3x3, 5x5 or 7x7)
+  1: number of input feature
+  8: nulber of output features
+ 32: width of the input image
+ 32: Height of th input image
+  3: ReLUPooling combination (0=>ReLU poolmax,1=>ReLU pool average, 2=> No ReLU Poolmax, 3=> NoRELu PoolAvg)

CNN_TiledLinearLayer: defines a Linear layer (dense layer). The parameters are, in order:

+ "Dense": The name of the generated function
+ 12: number of input features
+  5: width of the input image
+  5: Height of the input image
+ 10: Number of output features
+  1: Size of input data (0=> 8 bits, 1=> 16bits, 2=> 32bits)
+  0: Relu (0=> not activated)
+  0: Activate use of L3 memory for coefficients (0=> not activated)

### File Generation

In order to generate the CNNkernels files, type the following commands

define PATH to the auto-tiler libraries and generator

~~~~~sh
export TILE_SRC=../../../auto-tiler/source
~~~~~

Generate the tiler (using as input the CNN description in file Model_kernel.c)

~~~~~sh
gcc -o GenTile -I$TILE_SRC/GenTiling -I$TILE_SRC/StdTypes -I$TILE_SRC/CnnStdModel Model_kernel.c $TILE_SRC/CnnStdModel/CNN_Generator.c $TILE_SRC/GenTiling/LibTile.a
~~~~~

Execute the tiler

~~~~sh
./GenTile
~~~~

In addition to the CnnKernel files, the tiler will produce the following output:

~~~~~text
Loading Lib Kernel                                  KerSetInBias
Loading Lib Kernel                                 KerConv3x3_fp
Loading Lib Kernel                           KerDirectConv3x3_fp
Loading Lib Kernel                                 KerConv5x5_fp
Loading Lib Kernel                           KerDirectConv5x5_fp
Loading Lib Kernel                                 KerConvNxN_fp
Loading Lib Kernel                           KerDirectConvNxN_fp
Loading Lib Kernel                                    KerReLU_fp
Loading Lib Kernel                              KerMaxPool2x2_fp
Loading Lib Kernel                              KerAvgPool2x2_fp
Loading Lib Kernel                          KerReLUMaxPool2x2_fp
Loading Lib Kernel                        KerReLUMaxPool2x2_2_fp
Loading Lib Kernel                        KerReLUAvgPool2x2_2_fp
Loading Lib Kernel                   KerReLUMaxPool2x2_2_Even_fp
Loading Lib Kernel                   KerReLUMaxPool2x2_2_Drop_fp
Loading Lib Kernel                        KerReLUMaxPool2x2_3_fp
Loading Lib Kernel                        KerReLUAvgPool2x2_3_fp
Loading Lib Kernel                            KerLinearLayer_fps
Loading Lib Kernel                             KerLinearLayer_fp
Loading Lib Kernel                            KerLinearLayer_fpd
Loading Lib Kernel                        KerLinearLayerReLU_fps
Loading Lib Kernel                         KerLinearLayerReLU_fp
Loading Lib Kernel                        KerLinearLayerReLU_fpd
Loading Lib Kernel                                   HWCE_Enable
Loading Lib Kernel                                  HWCE_Disable
Loading Lib Kernel                              HWCE_GenericInit
Loading Lib Kernel                               HwCE_SetYinMode
Loading Lib Kernel                                 KerSetInBias2
Loading Lib Kernel                                 KerSetInBias3
Loading Lib Kernel               HWCE_ProcessOneTile3x3_MultiOut
Loading Lib Kernel                        HWCE_ProcessOneTile5x5
Loading Lib Kernel                        HWCE_ProcessOneTile7x7
Loading Lib Kernel                        HWCE_ProcessOneTile7x4
Kernel:            ConvLayer, Total Raw Memory: 7152 fits into L1 memory 51200. Promoting all kernel arguments to initialized buffers.
Kernel:            ConvLayer, Total Raw Memory: 8736 fits into L1 memory 51200. Promoting all kernel arguments to initialized buffers.
Kernel:                Dense, Total Raw Memory: 6640 fits into L1 memory 51200. Promoting all kernel arguments to initialized buffers.

Generating User Kernel                                 ConvLayer [ 1x  32x  32x 8]. Use Kernel Descriptor: KER_ARGS_ConvLayer_1
Generating User Kernel                                 ConvLayer [ 8x  14x  14x12]. Use Kernel Descriptor: KER_ARGS_ConvLayer_2
Generating User Kernel                                     Dense [ 1x   5x   5x 1]. Use Kernel Descriptor: 0 (user kernel is inlined)

Shared L1 Memory size (Bytes)             : Given: 51200, Used: 8736
L2 Memory size (Bytes)                    : 0
C Symbol for shared L1 Memory             : L1_Memory. Static, defined in CnnKernelsInit.c
C Symbol for L2 Memory                    : L2_Memory. Static, defined in CnnKernelsInit.c
C Symbol for kernels descriptors          : AllKernels
C Symbol for kernels arguments descriptors: AllKernelsArgs
Standard data types used by kernels       : KernelLibStdTypes.h
Basic kernels library                     : CNN_BasicKernels.h
Output Directory                          : .

The following files have been generated:
	                  CnnKernels.c Generated C code for the user kernels and the user kernels groups
	                  CnnKernels.h Header file for the generated C code
	              CnnKernelsInit.c Kernel descriptors constant initialization, shared L1 memory C definition
	              CnnKernelsInit.h Header file for kernel descriptors constant initialization

==> end of the output
~~~~~

The generated file using the actual Model_Kernel present in the cifar10 directory are saved as reference in the gen_lib_save directory, so they can be restored from here.

## Compile and run the application

### Single execution

To execute the application on the specific image contained in RGB.img, just type the following in the cifar10 directory:

~~~~~sh
	make clean all run platform=gvsoc
~~~~~

The output of the program is a set of 10 soft confidence values, one for each category. The maximal value is the category detected by the CNN.

~~~~~text
start main
open cam
start capture
cam started
cam stopped: acquisition performed
cluster master start
CNN  launched on cluster (8 cores)


 ============> cycles 165689


 feat 0: 5274  
 feat 1: 3805  
 feat 2: 11955  
 feat 3: 11183  
 feat 4: 9316  
 feat 5: 8641  
 feat 6: -56  
 feat 7: 9163  
 feat 8: -4294  
 feat 9: 4826  

found max 2
~~~~~

### Batch execution

To execute the application on the test set contained in test_img, just type the following:

~~~~~sh
	source script_run.sh
~~~~~

This will generate a report where the ground truth label, the found label and the number of cycles for execution are shown for each run.

~~~~~text
      label 6 found 6 cycles 171401
      label 9 found 7 cycles 171401
      label 9 found 7 cycles 171401
      label 4 found 4 cycles 171401
      label 1 found 1 cycles 171401
      label 1 found 1 cycles 171401
      label 2 found 2 cycles 171401
      label 7 found 7 cycles 171401
      label 8 found 8 cycles 171401
      label 3 found 2 cycles 171401
~~~~~

